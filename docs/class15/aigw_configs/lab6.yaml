mode: standalone
adminServer:
  address: :8080
server:
  address: :4141

# The routes determine on what URL path the AIGW is listening
routes:
  - path: /api/chat
    policy: arcadia_ai_policy
    timeoutSeconds: 600
    schema: openai

# What policy is applied to the route
policies:
  - name: arcadia_ai_policy
    profiles:
      - name: default

# To what LLM endpoint we forward the request to
services:
  - name: ollama
    executor: http
    config:
      endpoint: "http://ollama_public_ip:11434/api/chat"
      schema: ollama-chat

# What do we do with the request, at the moment we just forward it
profiles:
  - name: default
    responseStages:
      - name: protect
        steps:
          - name: pii-redactor

    services:
      - name: ollama


# Here we will find all our processor configuration
processors:
  - name: pii-redactor
    type: external
    config:
      endpoint: "http://aigw-processors-f5:8000"
      version: 1
      namespace: f5
    params:
      threshold: 0.2 # Default 0.2
      allow_rewrite: true # Default false
      denyset: ["EMAIL","PHONE_NUMBER","STREETADDRESS","ZIPCODE"]

